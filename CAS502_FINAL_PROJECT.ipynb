{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c45b988c-d5b8-47cd-becd-046627a6a445",
   "metadata": {
    "id": "4d121178-a13b-4140-94a8-8a0a04b0705d",
    "outputId": "24fe5d95-4af9-4478-89cf-09ec815bd275"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler \n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d8988f-3d08-4ee9-8380-5e7f2bbc41f6",
   "metadata": {},
   "source": [
    "# Explanations (for Brad)\n",
    "- test_train_split is a cool feature (module) of this library (sklearn). It splits the data into training and testing--usually an 80/20 split. \n",
    "- I'm familiar with what I've done in class - L1/L2 regressions. But I use random forests on Dataiku when dealing with non-linear regressions. I pulled this code from a book I frequently use: Machine Learning with PyTorch and Scikit_Learn, which offers links to great tutorials.\n",
    "- Mean Absolute Error gives us the absolute difference between actual length of stay and the predicted. This model's prediction is off by 1.24 days.\n",
    "- Mean Squared Error gives us the average of the squared difference between actual and predicted. It essentially penalizes large errors because they are squared. With this method, the model is off by 3.43 days. We could improve these numbers, but it could get complicated. We could also drop some of the columns that don't matter, like doctors' names. But when I look at this data visually, it's good to see the docs' names, because it could give us some insight into which doctors have the longest LOS. I'm less concerned with accuracy than I am with building a workable model. \n",
    "- R2 tells us how well the model explains variance in the target variable. The closer to 1, the better the model explains the variance. This model's R2 is .94, which is pretty good--the model fits the data. It explains 94% of the variance, essentially.\n",
    "- OneHotEncoder and StandardScaler: I'm not all that familiar with these modules inside sklearn. I pulled them from the same book I mentioned above. OneHotEncoding takes all of our categorical variables (e.g., doctors' names) and converts them into binary numbers and places each in a new category. Moreover, it ignores unknowns, like if we put a doctor's name in that it doesn't recognize--it will just ignore it. 'cat' (for category) was the label used in the book, so I stuck with it--cut and pasted, essentially.\n",
    "- StandardScaler: in the same \"pre-processing\" vein that sklearn does for us, StandardScaler transforms number columns ('num') to binary numbers as well, where 0 is the mean and 1 is the standard deviation. Basically, when numbers/integers are scaled like this, they all contribute evenly to the model. ColumnTransformer, then, is the function we call to pre-process categorical variables and numbers. It's pretty cool, actually.\n",
    "- Pipeline puts it all together for us. It pre-processes our data and then does the random forest regression on both training and test data. Very slick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f005b436-60cc-4ebd-a680-790209756636",
   "metadata": {
    "id": "4d121178-a13b-4140-94a8-8a0a04b0705d",
    "outputId": "24fe5d95-4af9-4478-89cf-09ec815bd275"
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_csv('/Users/davecooper/Documents/ASU/CAS502/Project/Hospital LOS.csv')\n",
    "\n",
    "# Define target and features\n",
    "X = data.drop(columns=['Stay (in days)', 'patientid']) # independent variables - this is our known\n",
    "y = data['Stay (in days)'] # this is our independent variable - or our target variable. Python extracted from the known and put into \n",
    "                            # the unknown or what we're trying to solve\n",
    "\n",
    "# Preprocess data\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "numeric_cols = X.select_dtypes(include=['number']).columns\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n",
    "    ('num', StandardScaler(), numeric_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05518aaf-de1d-4d22-a3bd-38c2d47524d7",
   "metadata": {},
   "source": [
    "- x = data.drop: stay in days and patientid. We needed to drop stay in days to make it a dependent variable--the target. When I first built the model (2 years ago), I left patientid alone, so the model used the values, which increased the errors. I could have gone back to the data and just deleted the column, but this is an easy fix.\n",
    "- y = data(stay in days): this is our target--our dependent variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ff1c74-0197-421c-9cfa-f6feead3b8e4",
   "metadata": {
    "id": "4d121178-a13b-4140-94a8-8a0a04b0705d",
    "outputId": "24fe5d95-4af9-4478-89cf-09ec815bd275"
   },
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d48344-22c8-45d7-9d3f-9eb73c88bbf0",
   "metadata": {},
   "source": [
    "- I've set the size of the test data to 20% of the data with test_size. The random state just ensures the same data split every time we run the model, or we'd get different results each time. The \"42\" is just arbitrary. In Python, it's also a joke. If you've ever read Hitchhiker's Guide to the Galaxy, 42 is the answer to life, the universe, and everything--LOL!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cd980a-d20f-41d4-9b2d-77fb660f949c",
   "metadata": {
    "id": "4d121178-a13b-4140-94a8-8a0a04b0705d",
    "outputId": "24fe5d95-4af9-4478-89cf-09ec815bd275"
   },
   "outputs": [],
   "source": [
    "# Build pipeline\n",
    "model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"MAE:\", mean_absolute_error(y_test, y_pred))\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"RÂ² Score:\", r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c74aaf-0c45-4767-ae2b-35ce506202c7",
   "metadata": {
    "id": "f9c74aaf-0c45-4767-ae2b-35ce506202c7"
   },
   "outputs": [],
   "source": [
    "new_patient = {\n",
    "    'Available Extra Rooms in Hospital': 3,\n",
    "    'Department': 'gynecology',\n",
    "    'Ward_Facility_Code': 'C',\n",
    "    'doctor_name': 'Dr. Oliva',\n",
    "    'staff_available': 15,\n",
    "    'Age': '31-40',\n",
    "    'gender': 'Female',\n",
    "    'Type of Admission': 'Emergency',\n",
    "    'Severity of Illness': 'Extreme',\n",
    "    'health_conditions': 'diabetes',\n",
    "    'Visitors with Patient': 2,\n",
    "    'Insurance': 'yes'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e158005-db98-468f-bb72-0b1ccf5e7900",
   "metadata": {
    "id": "3e158005-db98-468f-bb72-0b1ccf5e7900",
    "outputId": "ded3acd7-b786-46e3-f25e-9f8b1e2ee5cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Length of Stay (in days): 8.234666666666667\n"
     ]
    }
   ],
   "source": [
    "# Convert new patient data to DataFrame\n",
    "new_patient_df = pd.DataFrame([new_patient])\n",
    "\n",
    "# Predict length of stay\n",
    "predicted_stay = model.predict(new_patient_df)\n",
    "\n",
    "print(\"Predicted Length of Stay (in days):\", predicted_stay[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed02046-4009-4f15-ab9b-64fa0204a2ce",
   "metadata": {
    "id": "e484bd2a-f94b-4bc6-9cf7-ec6dc4961979"
   },
   "source": [
    "- Data frames: this used to be troubling for me. The new_patient data above is a \"dictionary.\" In a dictionary, keys (e.g., age) map to values (e.g., 31-40). Pandas takes dictionary data and transforms it into a data frame (e.g., excel spreadsheet). Sklearn requires data to be in a data frame format. If we didn't have that line of code in there, we'd get an error that tells us we have to convert the data to a data frame.\n",
    "- That's it. This is a pretty simple model--no for loops! "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
